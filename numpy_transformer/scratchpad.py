print('hello world!!!')

print('test code')

import tiktoken
import transformers

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained("google/gemma-2b-it")


# 
#  
#
#
#
#
#
#
#
#

enc = tiktoken.get_encoding("")
def get_tokens_from_text(tokenizer, input_text):
    # Convert Text into sub text and generate tokens
    # Use TikToken embedding for this
    return False

def get_token_id_from_tokens():
    return False

def get_token_embeddings():
    return False

class EmbeddingVector:
    def __init__():
        pass

class EmbeddingMatrix:
    def __init__():
        pass

def calculate_attention(embedding: EmbeddingMatrix) -> EmbeddingVector:
    return False

